{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9535294,"sourceType":"datasetVersion","datasetId":5807598}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport os\nimport torch as pt\nfrom torchvision import transforms\nfrom deepface import DeepFace\nimport mediapipe as mp\n\n# Define cosine similarity using PyTorch tensors\ndef cos_similarity(a, b):\n     cos_cal = pt.nn.CosineSimilarity(dim=1, eps=1e-10)\n     return cos_cal(a, b)\n\n# Function to process images and perform facial recognition\ndef process_images(number_camera, input_dir, target_img_path, model_face_detector, output_dir):\n    target_img = cv2.imread(target_img_path)\n    shape_face = [100, 75]  # Desired face shape for image processing\n    transform = transforms.ToTensor()\n\n    # Ensure target image is successfully loaded\n    if target_img is None:\n        print(f\"Error: Could not load target face image from {target_img_path}\")\n        return\n\n    # Set input size for face detection\n    model_face_detector.setInputSize([target_img.shape[1], target_img.shape[0]])\n    target_faces = model_face_detector.infer(target_img)\n\n    if target_faces.shape[0] == 0:\n        print(\"Error: No face detected in target image.\")\n        return\n\n    max_images_to_process = 3\n    folders_to_rename = {}\n\n    # Loop through cameras\n    for i in range(number_camera):\n        # Load tensor data\n        tensor_open = np.load(os.path.join(input_dir, str(i) + \".npy\"))\n\n        # Read information from corresponding text file\n        with open(os.path.join(input_dir, str(i) + \".txt\")) as i_o:\n            info_open = [line.rstrip() for line in i_o]\n\n        max_cos_value = 0\n        face_most_similar = -1\n        img_tensors = []\n\n        # Loop through tensor data to perform face verification\n        for ii in range(tensor_open.shape[0]):\n            img_tensor = tensor_open[ii]\n            img_tensors.append(img_tensor)\n\n            cam_id = info_open[ii].split(\" \")[0]\n            img_id = info_open[ii].split(\" \")[1]\n\n            # Save tensor image as temporary image for DeepFace\n            temp_img_path = os.path.join(output_dir, f\"temp_image_{i}_{ii}.png\")\n            cv2.imwrite(temp_img_path, np.rint(img_tensor * 255).astype(np.uint8))  # Chuyển tensor thành hình ảnh và lưu tạm\n\n            # Perform facial verification using DeepFace\n            verification_result = DeepFace.verify(\n                img1_path=target_img_path,\n                img2_path=temp_img_path,  \n                enforce_detection=False,\n                distance_metric=\"cosine\",\n                model_name=\"Facenet512\"\n            )\n\n            # Check if a match is found\n            if verification_result['verified']:\n                score = verification_result['distance']\n                if score < max_cos_value or max_cos_value == 0:\n                    max_cos_value = score\n                    face_most_similar = ii\n\n            # Save the most similar face\n            if face_most_similar != -1:\n                img = img_tensors[face_most_similar] \n                img_now = np.zeros((shape_face[0], shape_face[1], 3))\n\n                for channel in range(3):\n                    img_now[:, :, channel] = img[channel, :, :]\n\n                print(f\"Similarity Score: {score:.4f}\")\n                cv2.imwrite(os.path.join(output_dir, f\"{i}.png\"), np.rint(img_now * 255))\n                print(f\"Saved image to {os.path.join(output_dir, f'{i}.png')}\")\n\n# Function for detecting facial landmarks using Mediapipe\ndef detect_face_landmarks(img, mp_face_mesh):\n    \"\"\"\n    Detect facial landmarks using Mediapipe Face Mesh.\n    Returns True if sufficient landmarks are detected, otherwise False.\n    \"\"\"\n    cropped_face = img\n\n    if cropped_face.size == 0:\n        print(\"Warning: Cropped face is empty, skipping this face.\")\n        return False\n\n    with mp_face_mesh.FaceMesh(static_image_mode=True) as face_mesh:\n        result = face_mesh.process(cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB))\n        if result.multi_face_landmarks:\n            return True\n    return False\n\n# Example usage for process_test_images function:\ndef process_test_images(test_images, target_img_path, output_dir):\n    \"\"\"\n    Verifies if test images match the target image using DeepFace and saves the results.\n    Logs match status and similarity score for each test image.\n    \n    Parameters:\n    - test_images: List of paths to test images.\n    - target_img_path: Path to the target image for verification.\n    - output_dir: Directory to save the processed test images.\n    \"\"\"\n    \n    # Ensure output directory exists\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    # Loop through each test image and verify\n    for i, test_img_path in enumerate(test_images):\n        test_img = cv2.imread(test_img_path)\n        if test_img is None:\n            print(f\"Error: Could not load test image from {test_img_path}\")\n            continue\n\n        try:\n            # Perform face verification with DeepFace\n            verification_result = DeepFace.verify(\n                img1_path=target_img_path,\n                img2_path=test_img_path,\n                enforce_detection=False,  # Skip detection if faces are not found\n                model_name=\"Facenet512\",       # DeepFace model for verification\n                distance_metric=\"cosine\"  # Cosine distance metric for similarity\n            )\n            \n            # Check if a match is found and log result details\n            score = verification_result['distance']\n            if verification_result['verified']:\n                print(f\"Match found for test image {test_img_path}: Score = {score:.4f}\")\n            else:\n                print(f\"No match for test image {test_img_path}. Score = {score:.4f}\")\n        \n        except Exception as e:\n            print(f\"Error processing image {test_img_path}: {str(e)}\")\n            continue\n        \n        # Save the test image to output directory\n        output_img_path = os.path.join(output_dir, f\"test_result_{i}.png\")\n        cv2.imwrite(output_img_path, test_img)\n        print(f\"Test image saved to {output_img_path}\")\n\n# Example usage for the process_test_images function:\ntarget_img_path = \"/kaggle/input/data-test-img/test_img/1.jpg\"\ntest_images = [\n    \"/kaggle/input/data-test-img/test_img/2.jpg\",\n    \"/kaggle/input/data-test-img/test_img/3.jpg\", \"/kaggle/input/data-test-img/test_img/1.jpg\" ,\"/kaggle/input/data-test-img/test_img/5.jpg\"\n]\n\noutput_dir = \"/kaggle/working\"\n\nprocess_test_images(test_images, target_img_path, output_dir)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-03T02:08:31.155503Z","iopub.execute_input":"2024-10-03T02:08:31.155975Z","iopub.status.idle":"2024-10-03T02:08:35.637225Z","shell.execute_reply.started":"2024-10-03T02:08:31.155933Z","shell.execute_reply":"2024-10-03T02:08:35.636157Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"No match for test image /kaggle/input/data-test-img/test_img/2.jpg. Score = 0.6600\nTest image saved to /kaggle/working/test_result_0.png\nNo match for test image /kaggle/input/data-test-img/test_img/3.jpg. Score = 0.6427\nTest image saved to /kaggle/working/test_result_1.png\nMatch found for test image /kaggle/input/data-test-img/test_img/1.jpg: Score = 0.0000\nTest image saved to /kaggle/working/test_result_2.png\nNo match for test image /kaggle/input/data-test-img/test_img/5.jpg. Score = 0.8717\nTest image saved to /kaggle/working/test_result_3.png\n","output_type":"stream"}]}]}